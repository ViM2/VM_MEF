\chapter{Calcul efficient: qualité des résultats et efforts de calcul}\label{Ch-Amelio}


\medskip
\section{Amélioration d'un modèle: méthodes~$r$, $h$ et~$p$}\label{Sec-rhp}

Les indicateurs d'erreur ont pour but de nous indiquer si «nous sommes loin de la solution», afin de pouvoir modifier le modèle si besoin. Ainsi, par itérations successives, on pourra tendre vers une solution de plus en plus proche de la solution exacte.

Les indicateurs locaux nous permettent notamment de faire des modifications uniquement locales du modèles, i.e. uniquement là où il y en a besoin, par exemple en raffinant le maillage.

\medskip
Globalement, il existe trois stratégies pour améliorer la précision de la solution obtenue:
\begin{description}
\item[\textcolorblue{Méthode~$r$:}]\index{méthode~$r$} Pour un maillage et un type d'élément donné, il s'agit de déplacer les nœuds, en fonctions des indicateurs d'erreur, et donc sans impacter le nombre de degrés de liberté du système. Ainsi, la taille des éléments peut augmenter (maillage plus grossier) dans les zones les moins sollicitées et diminuer (maillage plus fin) dans les zones les plus sollicitées. On voit que la restriction de la méthode est qu'elle ne joue pas sur le nombre de nœuds, et que par conséquent, sans violer les contraintes de distorsion, elle est limitée.
\item[\textcolorblue{Méthode~$h$:}]\index{méthode~$h$} En conservant le même type d'élément, on les subdivise dans les zones les plus sollicitées selon le ou les indicateurs d'erreur choisis. Dans cette méthode, on augmente le nombre de nœuds afin de contrôler les erreurs et la précision du modèle. Il est nécessaire de se fixer une limite dans la précision recherchée afin de ne pas trop raffiner le maillage.
\item[\textcolorblue{Méthode~$p$:}]\index{méthode~$p$} À nombre d'éléments constant, dans les zones les plus sollicitées, on va modifier les éléments en introduisant des fonctions de formes polynomiales d'ordre plus élevé, dites hiérarchiques. La complexité du système est cette fois encore accrue.
\end{description}

\medskip
Évidemment, ces méthodes peuvent être combinées. La \textcolorblue{méthode -$hp$-}\index{méthode~$hp$} propose de modifier à la fois le maillage et
les fonctions d'interpolation. Elle semble aujourd'hui être la méthode optimale en terme
d'efficacité et de vitesse de convergence.

Notons que les méthodes -$r$- et -$h$- dépendent des capacités du mailleur automatique implémenté. De nombreux travaux existent sur le maillage automatique, nous n'entrerons pas dans ce détail.

\medskip
\section{Post-traitement}\index{post-traitement}\label{Sec-PT}

Une manière d'améliorer les résultats est de recourir à des méthodes dites de post-traitement, i.e. des méthodes qui, à partir des données issues de la résolution du système matriciel correspondant au problème, fournissent des données complémentaires ou améliorent toute ou partie des données déjà disponibles.

En fonction des problèmes (donc des données disponibles et des données souhaitées) de nombreuses méthodes existent. Elles sont généralement dédiées à un problème donné.

\medskip
Un exemple déjà abordé dans ce document est celui où, à partir des déplacement nodaux obtenus par un calcul éléments finis d'une structure mécanique composée de deux matériaux différents dans une discrétisation classique «en déplacements», on souhaite remonter aux contraintes à l'interface entre lesdits matériaux.

Une méthode déjà mentionnée est la méthode dite de «Reissner local»\index[aut]{Reissner (Max Erich, dit Eric), 1913-1996, Américain} qui consiste à intégrer les équations d'équilibre sous la forme mixte de Reissner,\index[aut]{Reissner (Max Erich, dit Eric), 1913-1996, Américain} mais uniquement sur des paires d'éléments ayant des propriété matérielles différentes et possédant une face commune.

On obtient alors un champ de contrainte complètement continu dont on ne retient que les composantes correspondant à la trace\index{trace} des contraintes, les autres étant calculées comme dans la méthode classique. On montre que l'on améliore grandement la qualité de l'approximation des contraintes aux interfaces, mêmes avec un maillage grossier.

\medskip
Un autre exemple serait, disposant d'un point de pression constant par élément, de calculer la pression en un point quelconque comme interpolation (linéaire ou non) à partir des points disponibles.

\medskip
Un troisième exemple serait à partir des données nodales dans un modèle unidimensionnel (poutre ou barre selon le cas), de remonter à la répartition des contraintes en un points quelconque de la structure (donc via les hypothèses faites dans le modèle sur la répartition des contraintes dans une section + via une interpolation lorsque l'on se trouve dans une section ne passant pas par un nœud)...

\input{./tex/ex4}% macro Ansys et poutre en U


\medskip
\section{Sous-structuration et simulation multi-échelles}\label{Sec-ssstruc}\index{sous-structuration}\index{multi-échelles}

Le fonctionnement des produits industriels met en jeu des phénomènes physiques à des échelles très différentes. La prise en compte de tous ces phénomènes dans les simulations numériques demanderait d'utiliser des modèles extrêmement détaillés, entraînant des coûts d'identification et/ou de calcul prohibitifs. La simulation multi-échelles\index{multi-échelles} est une réponse à cette problématique. Elle consiste à simuler chaque phénomène à l'échelle la plus pertinente, i.e. en utilisant plusieurs modèles de tailles et de finesses différentes; cela permet, grâce à des solveurs adaptés, de réaliser des simulations qui seraient inaccessibles par des approches plus directes.

\medskip
Imaginons que nous souhaitions calculer un avion, mais que, pour des raisons évidente de sécurité, nous ayons besoin d'obtenir une precision «boulon par boulon». On se doute bien que l'on ne peut mailler tout l'avion avec un tel niveau de détail... On recourt alors à une cascade de modèles de dimensions et de finesses différentes, allant de l'avion tout entier (mais modélisé relativement grossièrement) à des détails structuraux modélisés très finement (mais limités à de petites zones), comme montré sur la \fig{Fig-avion}.
\begin{figure}[ht]
\centering\includegraphics[height=60mm]{avion.eps}
\caption{Sous-structuration en aéronautique}\label{Fig-avion}
\end{figure}

La simulation est donc décomposée en différents niveaux, chacun représentant une échelle différente. Pour coordonner ces niveaux entre eux, on utilise généralement une \textcolorblue{approche} dite \textcolorblue{descendante}:\index{approche descendante} on commence par simuler le comportement global de l'avion, puis les résultats sont utilisés pour déterminer les conditions aux limites appliquées sur les niveaux inférieurs. Toutefois, il est parfois également nécessaire de combiner ces approches descendantes
à des \textcolorblue{approches ascendantes}:\index{approche ascendante} les résultats des simulations fines sont utilisés pour construire des modèles de comportements plus grossiers.

\medskip
De très nombreuses méthodologies multi-échelles existent et reposent toutes sur le fait de simuler chaque phénomène à l'échelle la plus pertinente. Pour cela, il est nécessaire:
\begin{enumerate}
  \item de \textcolorred{distinguer différentes échelles} dans la modélisation et dans la simulation;
  \item de \textcolorred{modéliser les relations existant} entre ces différentes échelles.
\end{enumerate}

\medskip
Considérons un problème comportant deux échelles. Le point 1 évoqué ci-dessus se traduit par le fait de disposer de deux modèles distincts:
\begin{itemize}
  \item \textcolorblue{Un modèle macroscopique}\index{modèle macroscopique}

	Il représente le produit et son environnement extérieur et est constitué d'une géométrie et d'un modèle de comportement relativement grossiers (puisque n'ayant pas vocation à représenter les phénomènes microscopiques);
  \item \textcolorblue{Un modèle microscopique}\index{modèle microscopique}

	Il possède une description géométrique et un maillage suffisamment fins ainsi que soit modélisé le comportement détaillé. Il ne comprend qu'une ou quelques «cellules types» de petites dimensions.

	Il est souvent possible, pour les matériaux notamment, de disposer d'hypothèses simplificatrices (telles que l'élasticité linéaire) permettant de se restreindre à une seule cellule type. Pour le cas des matériaux anisotropes constitués de plusieurs autres matériaux tels que les matériaux composites et fibreux, on se reportera au chapitre~\ref{Ch-Homog}. 

	Toutefois, il peut arriver que l'on ne dispose pas de telles hypothèses et il soit alors nécessaire de multiplier le nombre de cellules (jusqu'à parfois couvrir tout le modèle macro !)
\end{itemize}

\medskip
Le point 2 consiste donc à relier les deux échelles de modélisation.

En effet, les modèles macroscopique et microscopique ne sont pas indépendants puisqu'ils modélisent la même physique à des échelles différentes. Il est donc nécessaire qu'ils soient cohérents l'un vis-à-vis de l'autre, en tout point et à chaque instant de la simulation. Pour cette raison, les modélisations multi-échelles\index{multi-échelles} comportent des couplages, i.e. des modèles d'interactions, entre les échelles.

\medskipvm
Dans le cadre de la mécanique des solides déformables, on procède généralement comme suit:
\begin{itemize}
  \item Le modèle de comportement macroscopique:\index{modèle macroscopique} qui modélise des phénomènes se produisant «au cœur du matériau», doit correspondre à la relation contraintes/déformations observée sur la cellule microscopique;

  \item Le modèle de comportement microscopique:\index{modèle microscopique} qui traduisent la façon dont la cellule est sollicitée par son environnement extérieur, doivent correspondre à l'état de contraintes ou de déformations macroscopique.
\end{itemize}

Le modèle macroscopique ayant une résolution beaucoup plus grossière, la cohérence des deux modèles ne peut donc pas se traduire par une correspondance exacte, point par point, des conditions aux limites ou du comportement. Pour cette raison, la plupart des approches multi-échelles postulent que les quantités macroscopiques doivent correspondre à des «moyennes» des quantités microscopiques correspondantes, la définition mathématique exacte de cette moyenne variant fortement d'une approche à l'autre.

\medskip
\colorgreen On peut donc dire que:
\begin{itemize}
  \item Le modèle de comportement macroscopique\index{modèle macroscopique} d'un élément de volume est choisi égal au comportement moyen de la cellule microscopique correspondante, calculé en utilisant une technique d'homogénéisation;\index{homogénéisation}

  \item Les conditions aux limites microscopiques sont appliquées en moyenne, car les champs de contraintes ou de déplacements macroscopiques sont beaucoup trop grossiers.
\end{itemize}\colorblack

\medskip
Le problème est donc \textcolorred{d'échanger des données pertinentes entre les différentes échelles}, compte tenu des différentes résolutions des modèles.

\medskip
\textcolorred{Dans le sens microscopique vers macroscopique, on utilisera les techniques d'homogénéisation} \index{homogénéisation} dont il sera l'objet au chapitre~\ref{Ch-Homog}.

\medskip
\textcolorred{Dans le sens macroscopique vers microscopique, il s'agit donc de spécifier des conditions aux limites à appliquer sur le bord des cellules microscopiques, à partir d'une solution macroscopique.}

\textcolorgris{%
Les méthodes les plus simples se contentent d'imposer directement le champ de déplacements (ou de contraintes) macroscopique comme condition aux limites. Le modèle macroscopique ayant par définition une résolution beaucoup plus grossière que le modèle microscopique, il est incapable de capturer l'allure microscopique des déplacements ou des contraintes. Ces conditions aux limites sont donc souvent trop imprécises par rapport aux finalités du modèle microscopique. Cela peut dégrader fortement la qualité des résultats et donc restreindre le domaine de validité de ces approches.}

Pour palier ce problème, on écrit les conditions aux limites microscopiques de manière plus subtile en les décomposant en la somme d'un terme moyen et d'un terme de moyenne nulle. Ainsi, le champ microscopique~$u^m$ sera écrit~$u^m=u^M +v^m$ où~$u^M$ est le champ macroscopique (i.e. la moyenne du champ microscopique), et~$v^m$ est le reste (à moyenne nulle).
Notre problème devient donc de \textcolorred{déterminer le reste~$v^m$}, et c'est là que les méthodes divergent le plus. On distingue néanmoins deux grosses familles:
\begin{itemize}
  \item \textcolorblue{Condition de périodicité}\index{condition de périodicité}

	On postule que l'on connaît l'allure du reste. On peut alors enchaîner un calcul macroscopique avec un solveur spécifique puis un calcul microscopique avec un solveur classique;
  \item \textcolorblue{Couplage des cellules microscopiques}\index{couplage des cellules microscopiques}

	Lorsqu'il n'est pas si simple de «séparer» les échelles, alors il faut résoudre en même temps les deux problèmes microscopique et macroscopique avec échange de données.
\end{itemize}
Ces deux approches vont être un peu plus détaillées maintenant.




\medskip
\subsection{Condition de périodicité -- méthodes multi-niveaux}\index{condition de périodicité}\index{multi-niveaux}

Souvent, les méthodes multi-niveaux sont basées sur des conditions de périodicité inspirées de l'homogénéisation périodique.\index{homogénéisation} Ces conditions supposent que la partie microscopique du champ de déplacement, $v^m$, est périodique, i.e. est égale sur chaque paire de faces opposées de la cellule type considérée. La même hypothèse est formulée sur les contraintes. On obtient ainsi un ensemble de conditions aux limites permettant de déterminer entièrement la solution microscopique à partir d'une déformation (ou d'une contrainte) macroscopique imposée.

Le résultat microscopique ainsi obtenu est pertinent à deux conditions: 1) il faut que la microstructure soit effectivement périodique, et 2) que le principe de Saint-Venant\index[aut]{Saint-Venant (Adhémar Jean Claude Barré de -), 1797-1886, Français}\index{principe! de Saint-Venant} s'applique, i.e. que l'on se trouve suffisamment loin de la surface de la pièce (y compris des détails géométriques tels que des trous, des fissures...). Dans le cas contraire, des effets de bord peuvent affecter l'allure de la solution, qui n'est alors plus périodique: il faut donc recourir à d'autres modélisations.

\medskip
La simulation multi-niveaux\index{multi-niveaux} fait appel à deux types de modèles, chacun équipé de son solveur:
\begin{itemize}
  \item un modèle macroscopique\index{modèle macroscopique} ne possédant pas de relation de comportement du matériau prédéfinie, équipé d'un solveur éléments fini modifié;
  \item un ensemble de modèles microscopiques\index{modèle microscopique} ne possédant pas de conditions aux limites prédéfinies, équipés de solveurs éléments finis classiques.
\end{itemize}

En fait, le solveur éléments finis modifié est un solveur éléments finis classique avec une petite différence: à chaque fois que le solveur macroscopique a besoin du comportement d'un élément de volume quelconque, il envoie l'état de déformation macroscopique de cet élément au solveur microscopique. Ce dernier dispose alors toutes les données nécessaires pour simuler  numériquement son comportement à l'échelle microscopique. Il est donc capable de renvoyer l'état de contraintes macroscopiques, selon la décomposition mentionnée ci-dessus.
\textcolorgreen{Les cellules microscopiques étant pour ainsi dire «indépendantes», il est possible de recourir à des calculateur parallèles.}

Le domaine de validité de ces méthodes est bon dès que l'on sait faire des hypothèses réalistes sur l'allure de la solution microscopique. Ce n'est pas toujours le cas: par exemple, la fissuration, lorsqu'elle sort d'un cadre microscopique pour atteindre un cadre macroscopique, se prête très mal à cet exercice.
Le cas de la fissuration sera abordé au chapitre~\ref{Ch-rupt}.

\medskip\colorgreen
\textbf{En résumé:}

Les méthodes multi-niveaux abordent la simulation à l'échelle macroscopique\index{modèle macroscopique} et se «nourrissent» du comportement simulé à l'échelle microscopique.\index{modèle microscopique}

Dans les méthodes multi-niveaux,\index{multi-niveaux} l'emploi d'hypothèses de périodicité se traduit par des «sauts» de contraintes et de déplacements d'une cellule à l'autre; si les échelles sont mal séparées, ces sauts sont non négligeables. Ne correspondant \emph{a priori} pas à la physique, ils traduisent un écart avec la réalité.
\colorblack



\medskip
\subsection{Couplage des cellules microscopiques -- méthodes de décomposition de domaine}\index{couplage des cellules microscopiques}\index{décomposition de domaine}\label{Sec-dec}

Les méthodes multi-niveaux présentées au paragraphe précédent sont mises à mal lorsque le comportement microscopique «déborde» un peu sur le comportement macroscopique, i.e. lorsque les échelles ne sont pas suffisamment bien séparées. On recourt alors aux méthodes de décomposition de domaines,\index{décomposition de domaine} dont la validité est plus large, mais qui sont plus complexes.

\medskip
Puisque nous ne pouvons plus supposer une allure de la solution microscopique,\index{modèle microscopique} nous n'allons utiliser que les seules connaissance disponibles à priori: la continuité du champ de déplacements ainsi que la vérification par les contraintes du principe d'action-réaction. Il «suffit» donc d'écrire qu'à l'interface entre deux cellules microscopiques, il y a égalité des déplacements et nullité de la somme des traces\index{trace} des contraintes (on retrouve ce que nous avons déjà plusieurs fois évoqué avec l'état des contrainte à l'interface entre deux matériaux différents).

\medskip
La présence de couplages entre les cellules microscopiques\index{couplage des cellules microscopiques} (qui en quelque sorte correspond à une généralisation de la condition de périodicité du paragraphe précédent) change complètement le déroulement de la simulation par rapport aux méthodes multi-niveaux vues au paragraphe précédent. En effet, la prise en compte de ces couplages implique d'échanger directement des données entre les différents solveurs microscopiques, qui ne sont plus «indépendants». En contrepartie, cela permet de propager une information fine sur l'ensemble de la pièce et, ainsi, de se passer de l'hypothèse de séparation des échelles: il n'est plus nécessaire de modéliser séparément les phénomènes microscopiques et macroscopiques.

\medskip
Concrètement, les méthodes de décomposition de domaine\index{décomposition de domaine} sont des solveurs qui ont généralement un fonctionnement multi-échelles.\index{multi-échelles} Elles partent d'un modèle microscopique\index{modèle microscopique} du produit
décomposé en sous-structures, et consistent à coupler les sous-structures en échangeant des contraintes et des déplacements sur les interfaces. Des versions plus ou moins simples existent. Notons bien qu'il n'y a pas de modèle macroscopique dans une telle approche.

\medskip\colorgreen
\textbf{En résumé:}

Dans la décomposition de domaine,\index{décomposition de domaine} la simulation est abordée à l'échelle la plus fine: la sous-structuration et le problème grossier ne sont utilisés que pour améliorer l'efficacité de la résolution.

Une simulation par décomposition de domaine\index{décomposition de domaine} conduit toujours à un champ de déplacement microscopique continu sur toute la structure, et un champ de contraintes microscopique équilibré (au sens des éléments finis) sur toute la structure.
\colorblack

\medskip
\textcolorgris{Actuellement, la simulation multi-échelles\index{multi-échelles} est encore relativement peu répandue dans le monde de l'ingénierie. Elle représente en effet un changement considérable par rapport aux pratiques usuelles de simulation; de plus, la plupart des logiciels de calcul multi-échelles\index{multi-échelles} sont des outils développés par des chercheurs, qui n'ont pas encore l'ergonomie et la robustesse des solveurs utilisés dans l'industrie. Les industriels attendent donc l'apparition d'outils mieux adaptés à leurs problématiques avant d'envisager une utilisation plus fréquente de ces méthodes.}

\textcolorgris{Cependant, à plus long terme, la simulation multi-échelles\index{multi-échelles} suscite un intérêt considérable dans l'industrie: en rendant accessibles à la simulation des phénomènes qui ne peuvent actuellement être étudiés qu'expérimentalement,
elle constitue un pas important en direction du «virtual testing». Pour cette raison, elle fait toujours l'objet de nombreux projets de recherche. Ceux-ci concernent aussi bien la modélisation, avec notamment la mise au point de «matériaux virtuels» (qui ne sont rien d'autre que des modèles multi-échelles, notamment pour les matériaux composites), que les solveurs qui sont en constante évolution.}

\medskip
\section{Super-éléments}\index{super-élément}

\begin{histoire}
Originellement introduit dans l'aéronautique dans les années 60 (d'où le choix de la figure~\ref{Fig-avion}), le concept de sous-structuration\index{sous-structuration} répondait à trois motivations:
\begin{itemize}
  \item faciliter la division du travail:
	des sous-structures\index{sous-structure} avec des fonctions différentes (fuselage, ailes, train d'atterrissage...) pouvaient être traitées par des groupes d'experts différents. Chaque groupe pouvait à loisir améliorer, raffiner... sa partie tant que l'interface avec les autres parties restait inchangée.
  \item profiter de la répétition:
	en remarquant qu'une même structure peut contenir plusieurs sous-structures identiques, il est possible de diminuer le temps d'étude (par exemple symétrie des ailes...) 
  \item contourner les limitations des ordinateurs:
	les ordinateurs de l'époque atteignaient vite leurs limites (par exemple en terme de taille mémoire). Diviser une structure complexe, que l'on était incapable de calculer en une seule fois, permettait de sauvegarder des résultats sous-structure par sous-structure puis d'effectuer «l'assemblage» des résultats.
\end{itemize}
Si les deux premiers points sont toujours d'actualité, le troisième l'est moins, surtout depuis le recourt aux algorithmes parallèles.

C'est d'ailleurs le développement de procédures pour le calcul parallèle qui a conduit les mathématiciens appliqués au concept de sous-domaines, alors qu'ils devaient grouper des éléments pour des raisons de calcul.
\end{histoire}
\colorblack

\medskip
Dans ce paragraphe, nous allons parler du concept de super-élément, qui n'est qu'une application de ce qui a été présenté au paragraphe précédent.

\medskip
Un super-élément\index{super-élément} est un groupement d'éléments qui, après assemblage, peuvent être vus comme un élément individuel du point de vue du calcul. Cet assemblage peut ê tre requis pour des raisons de modélisation ou de calcul.

Pour constituer un super-éléments,\index{super-élément} les éléments groupés ne peuvent être pris au hasard. Ils doivent au moins constituer une «structure» en eux-même, mais d'autres conditions sont nécessaires qui seront détaillées plus loin.

Comme nous l'avons dit au paragraphe précédent, il y a deux voies duales pour considérer ce processus.
L'approche descendante consiste à considérer un super-élément comme constitué d'un ensemble d'éléments. On parle alors de macro-élément.\index{macro-élément} L'approche ascendante consiste à considérer un super-élément comme un sous-ensemble d'une structure complète. On parle alors de sous-structure.\index{sous-structure}\index{sous-structuration}

Finalement, quand parle-t-on de sous-structure ou de macro-élément?\index{macro-élément}\index{sous-structure}\index{sous-structuration} En fait, il n'y a pas de règle, et le terme générique de super-élément couvre tout le spectre depuis l'élément individuel jusqu'à la structure complète.

\medskip
\subsection{Condensation statique}\index{condensation statique}\label{Sec-condens}

En tant qu'assemblage de plusieurs éléments, un super-élément\index{super-élément} possède:
\begin{itemize}
  \item des degrés de liberté internes:
	qui ne sont pas connectés à des éléments n'appartenant pas au super-élément considéré.
	Les nœuds ayant des degrés de liberté internes sont dits nœuds internes.
  \item des degrés de liberté aux frontières:
	qui sont connectés à au moins une entité (élément, super-élément)
	n'appartenant pas au super-élément considéré.
\end{itemize}

L'opération consistant à éliminer tous les degrés de liberté internes est appelée \textcolorblue{condensation statique} ou simplement \textcolorblue{condensation}.\index{condensation statique}
\medskipvm
Regardons ce qui se passe d'un point de vue matriciel.
Pour cela, considérons que nous ayons à résoudre le système:
\begin{equation} \MM{K} \VV{q}=\VV{F}\end{equation}
Le vecteur~$\VV{q}$ se compose des composantes internes~$\VV{q_i}$ et des composantes
de frontière~$\VV{q_b}$, de sorte que le système, une fois réordonné s'écrit:
\begin{equation}
\MM*{\MM{K_{bb}} & \MM{K_{bi}}\\
\MM{K_{ib}} & \MM{K_{ii}}}
\VV*{\VV{q_b}\\\VV{q_i}}
=
\VV*{\VV{f_b}\\\VV{f_i}}
\end{equation}
Si la matrice~$\MM{K_{ii}}$ n'est pas singulière, alors la seconde équation peut être résolue en terme de variables internes en:
\begin{equation}
\VV{q_i} = \MMI{K_{ii}}\left(\VV{f_i}-\MM{K_{ib}}\VV{q_b}\right)
\end{equation}
En reportant cela dans la première équation, on obtient le système avec \textcolorblue{matrice de rigidité condensée}:\index{condensation statique}
\begin{equation}
\MM{\tilde{K}_{bb}}\VV{q_b} = \VV{\tilde{f}_b}
\end{equation}
avec:
\begin{equation}
\MM{\tilde{K}_{bb}}=\MM{K_{bb}} - \MM{K_{bi}}\MMI{K_{ii}}\MM{K_{ib}}
\quad \text{ et }\quad
\VV{\tilde{f}_b}=\VV{f_b} - \MM{K_{bi}}\MMI{K_{ii}}\VV{f_i}
\end{equation}
Après condensation, on peut donc bien considérer le super-élément, d'un point de vue calculatoire, comme un élément individuel.

\medskip
Notons que la matrice~$\MM{K_{ii}}$ n'est pas singulière si elle possède la \textcolorblue{condition de rang suffisant}, i.e. si elle ne contient que des modes à énergie nulle correspondant aux modes rigides (cette condition a déjà évoquée à propos de la validation des éléments). Si cela n'est pas le cas, le super-élément\index{super-élément} est dit \textcolorblue{flottant}, et peut quand même être traité (en utilisant les projecteurs et inverses généralisés, mais c'est un peu plus compliqué).

La condensation statique\index{condensation statique} est une opération matricielle appelée \textcolorblue{inversion partielle} ou \textcolorblue{élimination partielle} ou \textcolorblue{pseudo-inversion}.\index{pseudo-inversion}

\medskip
\subsection{Remonter aux degrés de liberté internes}

Une fois le système condensé résolu, on obtient les valeurs aux nœuds internes en réutilisant la formule:
\begin{equation}
\VV{q_i} = \MMI{K_{ii}}\left(\VV{f_i}-\MM{K_{ib}}\VV{q_b}\right)
\end{equation}

\medskip
\section{Pseudo-inversion et réanalyse}\index{pseudo-inversion}\label{Sec-PInv}

\textcolorgreen{On peut être amené, notamment lors de phases de conceptions, à devoir considérer plusieurs problèmes «relativement proches» les uns des autres (i.e. tester plusieurs configurations). On est alors tenté d'utiliser tout ou partie de la première modélisation afin de réaliser les suivantes.}

\medskip
L'idée de la méthode de réanalyse est d'analyser le comportement d'une structure élastique par éléments finis \textcolorblue{sans particulariser} le système d'équations final par la prise en compte de conditions cinématiques.

On obtient alors une solution générale de ce système faisant intervenir une \textcolorblue{matrice de rigidité régularisée}. La nature de cette matrice (somme d'une matrice bande et d'une matrice pleine) ne permet pas d'utiliser les méthodes les plus classiques et optimales de résolution, mais il est possible d'en développer d'autres permettant d'accéder à \textcolorblue{la quasi-inverse d'une matrice singulière semi-définie positive} (tout en profitant de son caractère bande).\index{pseudo-inversion}

Il est alors possible, tout en modifiant les conditions cinématiques et les chargements appliqués, de procéder à des réanalyses qui consistent alors simplement à résoudre des systèmes dits secondaires de tailles très inférieures au système global (mais un surcoût a été «payé» initialement pour calculer la pseudo-inverse).

Des problèmes de contact avec ou sans frottement entre solides élastiques peuvent bénéficier de cette méthode, ainsi que la modélisation du comportement élastique incompressible.


\medskip
\subsection{Modification du chargement uniquement}

Restons sur le problème structurel correspondant au système matriciel:
%une structure, de matrice de rigidité~$\MM{K}$, alors les déplacements de ses
%nœuds~$q$, lorsque cette structure est soumise au chargement~$F$ sont donnés par
%le système:
\begin{equation}
\MM{K} \VV{q} = \VV{F}
\end{equation}
où~$\MM{K}$ est de dimension~$n\times n$.

\medskip
Si l'on souhaite considérer plusieurs cas de chargement~$\VV{F_1},\ldots,\VV{F_k}$, on peut soit résoudre $k$ fois le système précédent, soit résoudre le système:
\begin{equation}
\MM{K} \MM{\overline{q}} =\MM{\overline{F}}
\end{equation}
où~$\MM{\overline{F}}$ est la matrice~$n\times k$ des~$k$ vecteurs de chargement, et~$\MM{\overline{q}}$ est la
matrice~$n\times k$ des~$k$ vecteurs solutions correspondants.

\medskip
Cette méthode, la plus simple des méthodes de réanalyse, permet malgré tout d'économiser des opérations.


\medskip
\subsection{Modification de la matrice}

Considérons maintenant le cas où ce n'est plus le chargement~$\VV{F}$ qui peut varier d'une analyse à l'autre, mais la matrice~$\MM{K}$.

On est amené à chercher une solution du système:
\begin{equation}
\left(\MM{K}+\Delta\MM{ K}\right)\VV{q}=\VV{F}
\end{equation}
en fonction de la solution du système non perturbé, i.e. à calculer~$\left(\MM{K}+\Delta\MM{K}\right)^{-1}$ en fonction des autres matrices. On rappelle que~$\Delta\MM{ K}$ est appelé \textcolorblue{perturbation} \index{perturbation} de la matrice~$\MM{K}$.

Certaines formules existent pour des modification mineures de la matrice~$\MM{K}$, mais nous ne les présenterons pas.

\medskip
\subsection{Modification des conditions cinématiques}

Nous ne considérons ici que des modifications des conditions cinématiques. Généralement, les conditions cinématiques sont prises en compte en supprimant ou en modifiant les équations de l'équilibre avant résolution, ce qui rend le système régulier. Nous avons vu que le système à résoudre (incluant les conditions cinématiques) revient à chercher le minimum de la forme quadratique:
\begin{equation}M=\frac12 \LL{q}\MM{K}\VV{q} -\LL{q}\VV{F}\end{equation}
Notons que l'on peut écrire les~$p$ conditions cinématiques sous la forme:
$\MM{C}\VV{q} = \VV{\delta}$
avec~$\MM{C}$ une matrice~$p\times n$, et~$\VV{q}$ et~$\VV{\delta}$ des vecteurs.

Nous avons également déjà vu que ces conditions peuvent être prises en compte par l'intermédiaire de~$p$ multiplicateurs de Lagrange\index{multiplicateurs de Lagrange}\index[aut]{Lagrange (Joseph Louis, comte de -), 1736-1813, Italien}~$\VV{\lambda}$ dans la fonctionnelle précédente qui devient alors:
\begin{equation}
M^*=\frac12 \LL{q}\MM{K}\VV{q} -\LL{q}\VV{F} - \LL{\lambda}\PP{\MM{C}\VV{q} - \VV{\delta}}
\end{equation}
Le système à résoudre est symétrique, régulier, mais non défini-positif.

\medskip
Pour pallier la lenteur des algorithmes disponibles pour la résolution numérique d'un tel système (méthode de Gauß ou de décomposition avec pivotage), il est préférable de \textcolorblue{régulariser} le système.

Pour cela, on s'appuie sur la connaissance de la matrice~$\MM{K}$: celle-ci est singulière d'ordre $r$, où~$r$ correspond aux mouvements de corps rigide, ou modes rigides. Cela veut également dire qu'elle possède~$(n-r)$ valeurs propres strictement positives (et~$r$ valeurs propres nulles).

\textcolorred{Il est évident qu'il faut au moins disposer de~$p\ge n$ conditions aux limites cinématiques pour que le système puisse admettre une solution.} C'est évidemment l'hypothèse que nous ferons (sinon le problème est mal posé).

\medskip
Nous considérons la matrice~$\MM{R}$ de dimension~$n\times r$ des~$r$ vecteurs propres de~$\MM{K}$ correspondant à la valeur propre nulle. Quitte à construire ces vecteurs (qui sont orthogonaux), nous les choisirons normés. On a alors:
\begin{equation}
\left\{
\begin{aligned}
&\MM{K}\MM{R}=\MM{0}\\
&\MMT{R}\MM{R}=\MM{I_r}
\end{aligned}
\right.
\end{equation}
On introduit la matrice:
\begin{equation} \MM{K_\alpha} = \MM{K}+\alpha \MM{R}\MMT{R} \end{equation}
qui, pour~$\alpha>0$ est régulière car symétrique et définie-positive.
Les colonnes de~$\MM{R}$ sont vecteurs propres de~$\MM{K_\alpha}$ pour la valeur propre~$\alpha$.

Dans le système~$\MM{K}\VV{q}=\VV{F}$, on remplace~$\MM{K}$ par~$\MM{K_\alpha}-\MM{R}\MMT{R}$, et en introduisant le
fait que~$\MM{K_\alpha}\MM{R}\MMT{R}=\alpha \MM{R}\MMT{R}$, on obtient finalement:
\begin{equation}
\MM{K_\alpha} \left(\MM{I_n}-\MM{R}\MMT{R}\right)\VV{q}=\VV{F}
\end{equation}
Si l'on change de variable en posant~$\VV{v}=\left(\MM{I_n}-\MM{R}\MMT{R}\right)\VV{q}$ ($\VV{v}$ est la projection de
$\VV{q}$ sur l'orthogonal du noyau de~$\MM{K}$), \textcolorblue{$\VV{v}$ devient l'inconnue du système régularisé}:
\begin{equation}
\MM{K_\alpha}\VV{v}=\VV{F}
\end{equation}
et l'on retrouvera la solution du système initial~$\VV{q}$ par:
\begin{equation}\VV{q}=\VV{v}+\MM{R}\MMT{R}\VV{q} = \MMI{K_\alpha}\VV{F}+\MM{R}\MMT{R}\VV{q}\end{equation}
\medskip
On peut remarquer que~$\MMI{K_\alpha}$, que l'on note~$\MM{S_\alpha}$, possède les mêmes valeurs propres que~$\MM{K_\alpha}$ (et donc les mêmes que~$\MM{K}$ et~$\MM{R}\MMT{R}$). On est donc naturellement amené à décomposer~$\MM{S_\alpha}$ comme:
\begin{equation} \MM{S_\alpha}=\MM{S}+\frac1\alpha \MM{R}\MMT{R}\end{equation}
avec~$\MM{S}\MM{R}=0$ et~$\MMT{R}\MM{S}=0$.

C'est cette matrice~$\MM{S}$ que l'on appelle \textcolorblue{quasi-inverse}\index{pseudo-inversion} de~$\MM{K}$, car:
\begin{equation} \MM{S}\MM{K} = \MM{K}\MM{S} = \MM{I} -\MM{R}\MMT{R}\end{equation}
Elle est de dimension~$n\times n$, symétrique, semi-définie positive (ses valeurs propres sont de même signe), admet les mêmes valeurs propres que~$\MM{K}$ et en particulier ceux de la valeur propre nulle dont~$R$ est une base, mais \textcolorred{elle ne possède pas de caractère bande}.

\bigskip
\textcolorgreen{Voici brossé, en quelques lignes, les idées principales de la méthode. Nous n'irons pas plus loin dans sa présentation.}

\medskip
On rappelle que l'intérêt de la méthode est qu'une fois une première étape consistant à intégrer les données relatives à la structure (géométrie, discrétisation, matériaux) réalisée, on peut alors effectuer autant de fois que nécessaire la seconde étape qui porte sur la prise en compte des chargements et conditions aux limites.

Notons qu'il est possible de modifier un peu la forme du système secondaire afin de pouvoir prendre en compte, lors de la seconde étape, des conditions plus complexes, comme des conditions mixtes par exemple...

\medskip
\subsection{Deux mots de statistiques}\label{Sec-PInv-Stat}

La méthode de réanalyse permet donc, pour un coût de calcul maîtrisé, d'obtenir les réponses à plusieurs problèmes proches.
Il se peut donc tout à fait que l'on désire faire varier un paramètre afin d'en étudier l'influence. Notons~$X$ ce paramètre variable, et~$Y=\mathcal{F}(X)$ la réponse du système correspondante.

Dans ce cas, si l'on connaît la répartition statistique de~$X$, i.e. sa densité de probabilité (encore appelée fonction de masse), alors on peut réaliser un échantillonnage correct de la plage dans laquelle ce paramètre varie afin de pouvoir obtenir des statistiques sur la réponse~$Y$.
Comme on raisonne sur un nombre de points finis, on utilisera donc une formulation discrète. Par exemple, une approximation de la moyenne de la réponse sera donnée par une formule de type:
\begin{equation}\label{Eq-PInv-Stat}
\E{Y}=\dfrac{\sum p_i\mathcal{F}(X_i)}{\sum p_i}
\end{equation}
où~$p_i$ est le poids, ou la pondération, correspondant à la fréquence à laquelle la valeur~$X_i$ du paramètre~$X$ apparaît.
On pourrait tout aussi bien, suite à l'analyse des réponses~$Y$, approcher celle-ci par une fonction quelconque, i.e. donner une forme analytique à la fonction~$\mathcal{F}$, et raisonner ensuite de manière continue.

Si c'est vraiment la caractérisation d'un système sous sollicitations aléatoires qui nous intéresse, alors on effectuera plutôt une analyse stochastique, et on se reportera au chapitre~\ref{Ch-stocha}.

\medskip
\section{Dérivées d'ordre supérieur}\index{dérivée!d'ordre supérieur}\label{Sec-Deriv}

Au paragraphe précédent, nous avons vu comment, sur une structure donnée, il était possible de prendre en compte plusieurs chargements et conditions aux limites cinématiques sans avoir à refaire tout le calcul.

\textcolorgreen{Dans le même état d'esprit, nous allons voir maintenant comment optimiser la forme d'une structure, sans refaire tous les calculs.}

\medskip
Considérons le cas d'une conception ayant pour but de déterminer la forme la plus adaptée selon certains critères (rigidité, déformée, contraintes, énergie transmise...). Chaque évaluation d'une fonction coût conduit à une analyse par éléments finis. L'utilisation de \textcolorblue{dérivées} par rapport à la géométrie, ou plus généralement par rapport à la fonction coût, permet de réduire ce nombre d'analyse.

En fait, peut-être contrairement à l'intuition, le calcul de ces dérivées est relativement peu coûteux; il n'est pas difficile et peut être fait automatiquement. Les dérivées d'ordre supérieur\index{dérivée!d'ordre supérieur} d'une fonction coût peuvent en fait être calculées avec autant de précision que la fonction elle-même. Ainsi, en un seul calcul, il est possible d'obtenir un développement de Taylor de la fonction coût, et donc d'éviter de nombreuses analyses.

\medskip
\subsection{Dérivées par rapport à la géométrie}\index{dérivée!par rapport à la géométrie}

En plus de considérer un domaine borné~$\Omega$ de~$\RR^n$, nous allons considérer une \textcolorblue{perturbation}\index{perturbation}~$V$ de~$\Omega$, et nous noterons:
\begin{equation} \Omega + V = (I+V)(\Omega);\quad V\in W^{1,\infty}(\Omega;\RR^n) \end{equation}
\medskipvm
Nous considérons la \textcolorblue{fonction coût}~${\mathbf J}(\Omega, u_\Omega)$ choisie pour décrire le problème d'optimisation. Cette fonction dépend donc naturellement du domaine~$\Omega$ et de la solution du problème sur ce domaine~$u_\Omega$. Nous allons donner un sens à la \textcolorblue{dérivée de la fonction coût par rapport aux variations du domaine}.

\medskip
Si l'on considère le cas simple~${\mathbf J}(\Omega,u)=\int_\Omega u$, alors il vient:
\begin{equation}
\dfrac{\dd{\mathbf J}}{\dd\Omega}(\Omega, u_v,V)=\dint_\Gamma u_\Omega V\cdot n + \dint_\Omega u'_{\Omega;v}
\end{equation}
avec une fois encore~$n$ la normale extérieure de~$\Gamma=\partial\Omega$, et:
\begin{equation}
u'_{\Omega;V}=\lim_{t\rightarrow0} \dfrac{u_{\Omega+tV}(x)-u_\Omega(x)}t, \quad\forall x\in\Omega
\end{equation}
La méthode de dérivation par transport conduit à:
\begin{equation}
\dfrac{\dd{\mathbf J}}{\dd\Omega}(\Omega, u_v,V)=\dint_\Gamma u_\Omega \dive V + \dint_\Omega \dot{u}_{\Omega;v}
\end{equation}
avec:
\begin{equation}
\dot{u}_{\Omega;V}=\lim_{t\rightarrow0} \dfrac{u_{\Omega+tV}\circ (I+tV)(x)-u_\Omega(x)}t,\quad \forall x\in\Omega
\end{equation}
On définit alors la \textcolorblue{dérivée de la fonction coût par rapport aux variations du domaine}
par:
\begin{equation}
\dfrac{\partial{\mathbf J}}{\partial\Omega}(\Omega, u,V) = \dint_\Gamma u V\cdot n
\end{equation}
La difficulté tient à ce que l'ensemble des domaines~$\Omega$ ne constitue pas un espace vectoriel. En effet, les perturbations ne s'ajoutent pas, ou au moins ne sont pas associatives:
$(\Omega+V)+W\ne(\Omega+W)+V$.

\medskip
\textcolorred{Toutefois, si l'on utilise un \textcolorblue{paramétrage} du domaine, il est alors possible d'utiliser les outils classiques du calcul différentiel dans les espaces normés.} On introduit alors le paramètre~$F$ par:
\begin{equation}
J(F,u)={\mathbf J}(F(\Omega),u\circ F^{-1}),\quad F\in W^{1,\infty}(\Omega;\RR^n)
\end{equation}
et l'on a alors~$(F+V)+W=(F+W)+V$.

La dérivée partielle de~$J$ par rapport au paramètre~$F$ est définie sans ambiguïté. Dans notre exemple, cette dérivée, prise au point~$F=I$ est:
\begin{equation}
\dfrac{\partial J}{\partial F}(I,u)\cdot V = \dint_\Omega u \dive V
\end{equation}
On pourra alors nous faire remarquer que:
\begin{equation}
\dfrac{\partial{\mathbf J}}{\partial\Omega}(\Omega, u,V)
\ne
\dfrac{\partial J}{\partial F}(I,u)\cdot V
\end{equation}
ce à quoi nous répondrons que c'est le prix à payer pour se ramener à un espace vectoriel. Cette démarche peut alors être généralisée aux ordres supérieurs.

\medskip
Nous parlerons plus en détail de dérivées par rapport à la géométrie dans le chapitre~\ref{Ch-Optim} sur l'optimisation, où sera abordée l'optimisation de forme.

\medskip
\subsection{Calcul des dérivées}

Nous n'entrons pas dans le détail, mais en cours de calcul se pose la question intéressante: obtient-on le même résultat si l'on discrétise d'abord et dérive ensuite? En fait, la réponse est oui, sous certaines conditions de régularité que nous ne mentionnerons pas dans le cadre de ce document.

\medskip
\textcolorgreen{Encore une fois, nous n'avons fait qu'effleurer le problème, juste pour «faire connaître» la méthode. Il nous semblait intéressant de présenter la notion de dérivée par rapport à la géométrie.}

De telles méthodes sont d'ores et déjà implémentées dans certains codes de calculs. Leur intérêt devrait apparaître clairement au lecteur (nous l'espérons).
